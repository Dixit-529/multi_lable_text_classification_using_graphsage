{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phPvDF_WTeH9"
      },
      "source": [
        "#Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoPU5EwJdlr4",
        "outputId": "ec8bfa44-5373-448d-aba2-5f8c614d1b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('models.py','wb').write(src)\n",
        "import models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F1Vbv5m3e9bW",
        "outputId": "816d497b-ba7d-4381-9916-9f29c18c1748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0ab756c-3618-4ca4-866e-c2dec5791af3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0ab756c-3618-4ca4-866e-c2dec5791af3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models.py to models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models import MAGNET"
      ],
      "metadata": {
        "id": "T_ve2FfBfng_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeHfYDNGoGka",
        "outputId": "888855c6-2209-4914-b4a8-bfef641daf80"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import reuters\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import hamming_loss, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import pickle\n",
        "import time\n",
        "import copy\n",
        "import magnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0stJr-VL1h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xLEwWKB6QtL"
      },
      "source": [
        "#Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8H5bRTsHPL"
      },
      "source": [
        "#Build adjacency matrix based on Co-Occurencies label\n",
        "def buildAdjacencyCOOC(data_label):\n",
        "  adj = data_label.T.dot(data_label).astype('float')\n",
        "  for i in range(len(adj)):\n",
        "    adj[i] = adj[i] / adj[i,i]\n",
        "\n",
        "  return torch.from_numpy(adj.astype('float32'))\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#Text cleaning function\n",
        "def preprocessingText(text, stop=stop):\n",
        "  text = text.lower() #text to lowercase\n",
        "  text = re.sub(r'&lt;', '', text) #remove '&lt;' tag\n",
        "  text = re.sub(r'<.*?>', '', text) #remove html\n",
        "  text = re.sub(r'[0-9]+', '', text) #remove number\n",
        "  text = \" \".join([word for word in text.split() if word not in stop]) #remove stopwords\n",
        "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctiation\n",
        "  text = re.sub(r'[^\\x00-\\x7f]', '', text) #remove non ASCII strings\n",
        "  for c in ['\\r', '\\n', '\\t'] :\n",
        "    text = re.sub(c, ' ', text) #replace newline and tab with tabs\n",
        "  text = re.sub('\\s+', ' ', text) #replace multiple spaces with one space\n",
        "  text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "  return text\n",
        "\n",
        "#Load Word Representation Vector\n",
        "def loadWRVModel(File):\n",
        "    print(\"Loading Word Representation Vector Model\")\n",
        "    f = open(File,'r')\n",
        "    WRVModel = {}\n",
        "    for line in f:\n",
        "        splitLines = line.split()\n",
        "        word = splitLines[0]\n",
        "        try:\n",
        "          wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "        except:\n",
        "          print(splitLines[1:])\n",
        "          print(len(splitLines[1:]))\n",
        "          break\n",
        "        WRVModel[word] = wordEmbedding\n",
        "    print(len(WRVModel),\" words loaded!\")\n",
        "    return WRVModel\n",
        "\n",
        "\n",
        "def check_accuracy(model, label_embedding, X, y):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    out = model(X, label_embedding)\n",
        "    y_pred = torch.sigmoid(out.detach()).round().cpu()\n",
        "    f1score = f1_score(y, y_pred, average='micro')\n",
        "    hammingloss = hamming_loss(y, y_pred)\n",
        "\n",
        "  return hammingloss, f1score\n",
        "\n",
        "def train(model,\n",
        "          X_train,\n",
        "          X_test,\n",
        "          label_embedding,\n",
        "          y_train,\n",
        "          y_test,\n",
        "          total_epoch=250,\n",
        "          batch_size=250,\n",
        "          learning_rate=0.001,\n",
        "          save_path='./model.pt',\n",
        "          state=None):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_data = DataLoader(dataset(X_train, y_train), batch_size=batch_size)\n",
        "  X_test = X_test.to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  label_embedding= label_embedding.to(device)\n",
        "\n",
        "  if state:\n",
        "    state = torch.load(state)\n",
        "    model = model.load_state_dict(state['last_model'])\n",
        "    optimizer = optimizer.load_state_dict(state['optimizer'])\n",
        "\n",
        "  else:\n",
        "    model = model.to(device)\n",
        "    state = dict()\n",
        "    state['microf1'] = []\n",
        "    state['hammingloss'] = []\n",
        "    state['val_hammingloss'] = []\n",
        "    state['val_microf1'] = []\n",
        "    state['epoch_time'] = []\n",
        "\n",
        "  epoch = 1\n",
        "\n",
        "  best_train = 0\n",
        "  best_val = 0\n",
        "\n",
        "  while epoch <= total_epoch:\n",
        "    running_loss = 0\n",
        "    y_pred = []\n",
        "    epoch_time = 0\n",
        "    model.train()\n",
        "    for index, (X, y) in enumerate(train_data):\n",
        "\n",
        "      t = time.time()\n",
        "\n",
        "      #forward\n",
        "      out = model(X.to(device), label_embedding)\n",
        "      loss = criterion(out, y.to(device))\n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(model.parameters(), max_norm=10)\n",
        "\n",
        "      #update\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_time += time.time() - t\n",
        "      y_pred.append(torch.sigmoid(out.detach()).round().cpu())\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    y_pred = torch.vstack(y_pred)\n",
        "    f1score = f1_score(y_train, y_pred, average='micro')\n",
        "    hammingloss = hamming_loss(y_train, y_pred)\n",
        "    val_hamming, val_f1score = check_accuracy(model, label_embedding, X_test, y_test)\n",
        "\n",
        "    state['microf1'].append(f1score)\n",
        "    state['hammingloss'].append(hammingloss)\n",
        "    state['val_microf1'].append(val_f1score)\n",
        "    state['epoch_time'].append(epoch_time)\n",
        "    state['val_hammingloss'].append(val_hamming)\n",
        "\n",
        "    state['optimizer'] = optimizer.state_dict()\n",
        "    state['last_model'] = model.state_dict()\n",
        "\n",
        "\n",
        "    if(best_train < f1score):\n",
        "      state['model_best_train'] = copy.deepcopy(model.state_dict())\n",
        "      best_train = f1score\n",
        "      state['best_train'] = best_train\n",
        "\n",
        "    if(best_val < val_f1score):\n",
        "      state['model_best_val'] = copy.deepcopy(model.state_dict())\n",
        "      best_val = val_f1score\n",
        "      state['best_val'] = best_val\n",
        "\n",
        "    torch.save(state, save_path)\n",
        "    print('epoch:{} loss:{:.5f} hamming_loss:{:.5f} micro_f1score:{:.5f} val_hamming_loss:{:.5f} val_micro_f1score:{:.5f}'.\n",
        "          format(epoch, running_loss, hammingloss, f1score, val_hamming, val_f1score))\n",
        "    epoch+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgZvCUaKY-xZ"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1PuvFDqT2Dv"
      },
      "source": [
        "## Load Raw Dataset (Reuters-21578)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD3nYHOGiwSQ",
        "outputId": "e11e5a07-b9de-4987-8906-4e09e6c82ada"
      },
      "source": [
        "data_train = pd.read_pickle('./train.pickle')\n",
        "data_test = pd.read_pickle('./test.pickle')\n",
        "\n",
        "text_train = data_train.text.values\n",
        "text_test = data_test.text.values\n",
        "\n",
        "y_train = torch.from_numpy(np.vstack(data_train.onehot_label.values)).float()\n",
        "y_test = torch.from_numpy(np.vstack(data_test.onehot_label.values)).float()\n",
        "\n",
        "print('Train label shape {}'.format(y_train.shape))\n",
        "print('Test label shape {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label shape torch.Size([7769, 90])\n",
            "Test label shape torch.Size([3019, 90])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ-0B4vnZJpB"
      },
      "source": [
        "#Load MultilabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJ0YUzGZTO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03123fb-bb97-4ab6-c3ca-f8fccf36466b"
      },
      "source": [
        "with open('./multilabelbinarizer.pickle', 'rb') as file:\n",
        "  mlb = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RminIPRXkY8"
      },
      "source": [
        "#Build Word Representation Vector Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3L7jlurXpjk",
        "outputId": "2a9a65d9-7b94-453f-e434-d02d954ff403"
      },
      "source": [
        "WRVModel = loadWRVModel('./glove.6B.300d.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Word Representation Vector Model\n",
            "17783  words loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjxasUuZ4lRi"
      },
      "source": [
        "#Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq5ref4z4oCq"
      },
      "source": [
        "## Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIAPLVCmox6A",
        "outputId": "534b9e1e-f2b4-4d9e-dda2-6fc99cd2750d"
      },
      "source": [
        "preprocessed_text_train = [preprocessingText(text) for text in text_train]\n",
        "preprocessed_text_test = [preprocessingText(text) for text in text_test]\n",
        "\n",
        "print('BEFORE CLEANING: {}'.format(text_train[0]))\n",
        "print('AFTER CLEANING: {}'.format(preprocessed_text_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE CLEANING: BAHIA COCOA REVIEW\n",
            "  Showers continued throughout the week in\n",
            "  the Bahia cocoa zone, alleviating the drought since early\n",
            "  January and improving prospects for the coming temporao,\n",
            "  although normal humidity levels have not been restored,\n",
            "  Comissaria Smith said in its weekly review.\n",
            "      The dry period means the temporao will be late this year.\n",
            "      Arrivals for the week ended February 22 were 155,221 bags\n",
            "  of 60 kilos making a cumulative total for the season of 5.93\n",
            "  mln against 5.81 at the same stage last year. Again it seems\n",
            "  that cocoa delivered earlier on consignment was included in the\n",
            "  arrivals figures.\n",
            "      Comissaria Smith said there is still some doubt as to how\n",
            "  much old crop cocoa is still available as harvesting has\n",
            "  practically come to an end. With total Bahia crop estimates\n",
            "  around 6.4 mln bags and sales standing at almost 6.2 mln there\n",
            "  are a few hundred thousand bags still in the hands of farmers,\n",
            "  middlemen, exporters and processors.\n",
            "      There are doubts as to how much of this cocoa would be fit\n",
            "  for export as shippers are now experiencing dificulties in\n",
            "  obtaining +Bahia superior+ certificates.\n",
            "      In view of the lower quality over recent weeks farmers have\n",
            "  sold a good part of their cocoa held on consignment.\n",
            "      Comissaria Smith said spot bean prices rose to 340 to 350\n",
            "  cruzados per arroba of 15 kilos.\n",
            "      Bean shippers were reluctant to offer nearby shipment and\n",
            "  only limited sales were booked for March shipment at 1,750 to\n",
            "  1,780 dlrs per tonne to ports to be named.\n",
            "      New crop sales were also light and all to open ports with\n",
            "  June/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\n",
            "  under New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\n",
            "  per tonne FOB.\n",
            "      Routine sales of butter were made. March/April sold at\n",
            "  4,340, 4,345 and 4,350 dlrs.\n",
            "      April/May butter went at 2.27 times New York May, June/July\n",
            "  at 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\n",
            "  2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\n",
            "  2.27 times New York Dec, Comissaria Smith said.\n",
            "      Destinations were the U.S., Covertible currency areas,\n",
            "  Uruguay and open ports.\n",
            "      Cake sales were registered at 785 to 995 dlrs for\n",
            "  March/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\n",
            "  New York Dec for Oct/Dec.\n",
            "      Buyers were the U.S., Argentina, Uruguay and convertible\n",
            "  currency areas.\n",
            "      Liquor sales were limited with March/April selling at 2,325\n",
            "  and 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\n",
            "  York July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\n",
            "  Sept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\n",
            "  said.\n",
            "      Total Bahia sales are currently estimated at 6.13 mln bags\n",
            "  against the 1986/87 crop and 1.06 mln bags against the 1987/88\n",
            "  crop.\n",
            "      Final figures for the period to February 28 are expected to\n",
            "  be published by the Brazilian Cocoa Trade Commission after\n",
            "  carnival which ends midday on February 27.\n",
            "  \n",
            "\n",
            "\n",
            "AFTER CLEANING: bahia cocoa review shower continued throughout week bahia cocoa zone alleviating drought since early january improving prospect coming temporao although normal humidity level restored comissaria smith said weekly review dry period mean temporao late year arrival week ended february bag kilo making cumulative total season mln stage last year seems cocoa delivered earlier consignment included arrival figure comissaria smith said still doubt much old crop cocoa still available harvesting practically come end total bahia crop estimate around mln bag sale standing almost mln hundred thousand bag still hand farmer middleman exporter processor doubt much cocoa would fit export shipper experiencing dificulties obtaining bahia superior certificate view lower quality recent week farmer sold good part cocoa held consignment comissaria smith said spot bean price rose cruzados per arroba kilo bean shipper reluctant offer nearby shipment limited sale booked march shipment dlrs per tonne port named new crop sale also light open port junejuly going dlrs dlrs new york july augsept dlrs per tonne fob routine sale butter made marchapril sold dlrs aprilmay butter went time new york may junejuly dlrs augsept dlrs time new york sept octdec dlrs time new york dec comissaria smith said destination u covertible currency area uruguay open port cake sale registered dlrs marchapril dlrs may dlrs aug time new york dec octdec buyer u argentina uruguay convertible currency area liquor sale limited marchapril selling dlrs junejuly dlrs time new york july augsept dlrs time new york sept octdec time new york dec comissaria smith said total bahia sale currently estimated mln bag crop mln bag crop final figure period february expected published brazilian cocoa trade commission carnival end midday february\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6CbF8ci4yW2"
      },
      "source": [
        "##Text to Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8rCpqQC4OHq"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_text_train)\n",
        "\n",
        "sequences_text_train = tokenizer.texts_to_sequences(preprocessed_text_train)\n",
        "sequences_text_test = tokenizer.texts_to_sequences(preprocessed_text_test)\n",
        "\n",
        "X_train = torch.from_numpy(pad_sequences(sequences_text_train, maxlen=128))\n",
        "X_test = torch.from_numpy(pad_sequences(sequences_text_test, maxlen=128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZi_UZbg43uw"
      },
      "source": [
        "## Build Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7_sCNk3vQvD",
        "outputId": "92578464-5870-48a5-f729-8f8dcf29605c"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = torch.zeros(VOCAB_SIZE, 300)\n",
        "\n",
        "unk = 0\n",
        "for i in range(1, VOCAB_SIZE):\n",
        "  word = tokenizer.index_word[i]\n",
        "  if word in WRVModel.keys():\n",
        "    tensor = torch.from_numpy(WRVModel[word]).float()\n",
        "    if tensor.size(0)<300:\n",
        "      # Calculate the number of zeros to add\n",
        "      num_zeros = 300 - tensor.size(0)\n",
        "\n",
        "      # Pad the tensor with zeros to reach a size of 300\n",
        "      embedding_matrix[i] = torch.cat((tensor, torch.zeros(num_zeros)), dim=0)\n",
        "    elif tensor.size(0)>300:\n",
        "      embedding_matrix[i] = tensor[:300]\n",
        "    else:\n",
        "      embedding_matrix[i]= tensor\n",
        "  else:\n",
        "    unk +=1\n",
        "print('VOCAB_SIZE : {}'.format(VOCAB_SIZE))\n",
        "print('TOTAL OF UNKNOWN WORD : {}'.format(unk))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB_SIZE : 25306\n",
            "TOTAL OF UNKNOWN WORD : 16073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZHdtuWH6kiT"
      },
      "source": [
        "#Preparing Graph Attention Networks Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhxTcQ_u6sUc"
      },
      "source": [
        "## Label Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URGNwS1hP_fr",
        "outputId": "081292b3-9503-4759-a3a6-6aef047a0832"
      },
      "source": [
        "label_embedding = torch.zeros(90,300)\n",
        "\n",
        "for index, label in enumerate(mlb.classes_):\n",
        "  words = label.split('-')\n",
        "  num_of_words = len(words)\n",
        "\n",
        "  for sublabel in words:\n",
        "    if sublabel in WRVModel.keys():\n",
        "      label_embedding[index] +=  torch.from_numpy(WRVModel[sublabel])\n",
        "  label_embedding[index] = label_embedding[index]/num_of_words\n",
        "\n",
        "print(label_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.5990, -0.3234, -0.2749,  ...,  0.6343,  0.5300,  0.0299],\n",
            "        [-0.4541, -0.1300, -0.5178,  ..., -1.1637, -0.2056, -0.3177]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PvT83CK66F-"
      },
      "source": [
        "##Adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhYLvfvTtZOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097ab7f4-6e4f-4cea-c595-84cd537e9afb"
      },
      "source": [
        "adjacency = buildAdjacencyCOOC(y_train.numpy())\n",
        "print(adjacency)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0012],\n",
            "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0286],\n",
            "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
            "        [0.0952, 0.0476, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0dSc09x7lGm"
      },
      "source": [
        "#Preparing DataLoader and Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uoQlm38OS5S"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vePGeWyvocZ"
      },
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x  = x\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi7g_VSYOYny"
      },
      "source": [
        "##Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apRrzy6cWzN5"
      },
      "source": [
        "model = MAGNET(300, 250, adjacency, embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvY8vULwSbXB"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTh-66uJSnij"
      },
      "source": [
        "##Configure Save PATH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC2_KVL5SfG-"
      },
      "source": [
        "save_path = './train_result.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwv_OW8zSx7W"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XeYrWVgvYrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c6ea5a-9ccd-46f3-8262-c94248b89ddc"
      },
      "source": [
        "train(model, X_train, X_test, label_embedding, y_train, y_test, save_path=save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1 loss:4.39042 hamming_loss:0.02719 micro_f1score:0.01808 val_hamming_loss:0.01378 val_micro_f1score:0.00000\n",
            "epoch:2 loss:2.33174 hamming_loss:0.01355 micro_f1score:0.06069 val_hamming_loss:0.01199 val_micro_f1score:0.28465\n",
            "epoch:3 loss:1.97842 hamming_loss:0.01264 micro_f1score:0.23179 val_hamming_loss:0.01168 val_micro_f1score:0.37181\n",
            "epoch:4 loss:1.77476 hamming_loss:0.01148 micro_f1score:0.35937 val_hamming_loss:0.01148 val_micro_f1score:0.40496\n",
            "epoch:5 loss:1.68145 hamming_loss:0.01112 micro_f1score:0.38069 val_hamming_loss:0.01219 val_micro_f1score:0.38945\n",
            "epoch:6 loss:1.59242 hamming_loss:0.01085 micro_f1score:0.40327 val_hamming_loss:0.01074 val_micro_f1score:0.42272\n",
            "epoch:7 loss:1.48178 hamming_loss:0.00984 micro_f1score:0.47264 val_hamming_loss:0.00826 val_micro_f1score:0.58946\n",
            "epoch:8 loss:1.42711 hamming_loss:0.01032 micro_f1score:0.46852 val_hamming_loss:0.01003 val_micro_f1score:0.46818\n",
            "epoch:9 loss:1.33513 hamming_loss:0.00917 micro_f1score:0.54642 val_hamming_loss:0.00791 val_micro_f1score:0.61062\n",
            "epoch:10 loss:1.23943 hamming_loss:0.00851 micro_f1score:0.59082 val_hamming_loss:0.01003 val_micro_f1score:0.43523\n",
            "epoch:11 loss:1.20475 hamming_loss:0.00831 micro_f1score:0.60143 val_hamming_loss:0.00794 val_micro_f1score:0.60664\n",
            "epoch:12 loss:1.16325 hamming_loss:0.00807 micro_f1score:0.62042 val_hamming_loss:0.00758 val_micro_f1score:0.63188\n",
            "epoch:13 loss:1.13451 hamming_loss:0.00800 micro_f1score:0.62725 val_hamming_loss:0.00755 val_micro_f1score:0.62958\n",
            "epoch:14 loss:1.16794 hamming_loss:0.00806 micro_f1score:0.61590 val_hamming_loss:0.00742 val_micro_f1score:0.65086\n",
            "epoch:15 loss:1.10176 hamming_loss:0.00768 micro_f1score:0.64686 val_hamming_loss:0.00739 val_micro_f1score:0.64686\n",
            "epoch:16 loss:1.06449 hamming_loss:0.00742 micro_f1score:0.66242 val_hamming_loss:0.00690 val_micro_f1score:0.68692\n",
            "epoch:17 loss:1.03637 hamming_loss:0.00724 micro_f1score:0.66954 val_hamming_loss:0.00674 val_micro_f1score:0.69749\n",
            "epoch:18 loss:1.01955 hamming_loss:0.00711 micro_f1score:0.68051 val_hamming_loss:0.00710 val_micro_f1score:0.67278\n",
            "epoch:19 loss:1.00028 hamming_loss:0.00701 micro_f1score:0.68924 val_hamming_loss:0.00742 val_micro_f1score:0.63782\n",
            "epoch:20 loss:1.01928 hamming_loss:0.00716 micro_f1score:0.67877 val_hamming_loss:0.00676 val_micro_f1score:0.68773\n",
            "epoch:21 loss:0.96763 hamming_loss:0.00675 micro_f1score:0.70101 val_hamming_loss:0.00676 val_micro_f1score:0.68635\n",
            "epoch:22 loss:1.00444 hamming_loss:0.00711 micro_f1score:0.68444 val_hamming_loss:0.00644 val_micro_f1score:0.71019\n",
            "epoch:23 loss:0.97396 hamming_loss:0.00683 micro_f1score:0.69977 val_hamming_loss:0.00669 val_micro_f1score:0.69456\n",
            "epoch:24 loss:0.96590 hamming_loss:0.00662 micro_f1score:0.71345 val_hamming_loss:0.00661 val_micro_f1score:0.69827\n",
            "epoch:25 loss:0.91954 hamming_loss:0.00632 micro_f1score:0.72805 val_hamming_loss:0.00628 val_micro_f1score:0.72941\n",
            "epoch:26 loss:0.91506 hamming_loss:0.00625 micro_f1score:0.73091 val_hamming_loss:0.00639 val_micro_f1score:0.71487\n",
            "epoch:27 loss:0.88818 hamming_loss:0.00633 micro_f1score:0.73026 val_hamming_loss:0.00638 val_micro_f1score:0.71320\n",
            "epoch:28 loss:0.86471 hamming_loss:0.00601 micro_f1score:0.74367 val_hamming_loss:0.00608 val_micro_f1score:0.73461\n",
            "epoch:29 loss:0.85074 hamming_loss:0.00595 micro_f1score:0.74798 val_hamming_loss:0.00655 val_micro_f1score:0.70144\n",
            "epoch:30 loss:0.87568 hamming_loss:0.00603 micro_f1score:0.74426 val_hamming_loss:0.00626 val_micro_f1score:0.71803\n",
            "epoch:31 loss:0.85280 hamming_loss:0.00592 micro_f1score:0.74979 val_hamming_loss:0.00587 val_micro_f1score:0.74594\n",
            "epoch:32 loss:0.82984 hamming_loss:0.00580 micro_f1score:0.75572 val_hamming_loss:0.00603 val_micro_f1score:0.74730\n",
            "epoch:33 loss:0.82726 hamming_loss:0.00576 micro_f1score:0.75903 val_hamming_loss:0.00609 val_micro_f1score:0.73809\n",
            "epoch:34 loss:0.83651 hamming_loss:0.00589 micro_f1score:0.75227 val_hamming_loss:0.00589 val_micro_f1score:0.74640\n",
            "epoch:35 loss:0.79886 hamming_loss:0.00562 micro_f1score:0.76656 val_hamming_loss:0.00572 val_micro_f1score:0.76615\n",
            "epoch:36 loss:0.79233 hamming_loss:0.00553 micro_f1score:0.76994 val_hamming_loss:0.00563 val_micro_f1score:0.76493\n",
            "epoch:37 loss:0.76584 hamming_loss:0.00527 micro_f1score:0.78189 val_hamming_loss:0.00552 val_micro_f1score:0.77374\n",
            "epoch:38 loss:0.76167 hamming_loss:0.00532 micro_f1score:0.77999 val_hamming_loss:0.00576 val_micro_f1score:0.75845\n",
            "epoch:39 loss:0.75676 hamming_loss:0.00533 micro_f1score:0.77990 val_hamming_loss:0.00572 val_micro_f1score:0.75933\n",
            "epoch:40 loss:0.74990 hamming_loss:0.00526 micro_f1score:0.78410 val_hamming_loss:0.00577 val_micro_f1score:0.76250\n",
            "epoch:41 loss:0.73829 hamming_loss:0.00510 micro_f1score:0.79105 val_hamming_loss:0.00560 val_micro_f1score:0.76359\n",
            "epoch:42 loss:0.72377 hamming_loss:0.00511 micro_f1score:0.79065 val_hamming_loss:0.00551 val_micro_f1score:0.76876\n",
            "epoch:43 loss:0.71797 hamming_loss:0.00508 micro_f1score:0.79177 val_hamming_loss:0.00562 val_micro_f1score:0.77089\n",
            "epoch:44 loss:0.71772 hamming_loss:0.00500 micro_f1score:0.79700 val_hamming_loss:0.00565 val_micro_f1score:0.77323\n",
            "epoch:45 loss:0.71419 hamming_loss:0.00511 micro_f1score:0.79295 val_hamming_loss:0.00547 val_micro_f1score:0.77451\n",
            "epoch:46 loss:0.70028 hamming_loss:0.00484 micro_f1score:0.80477 val_hamming_loss:0.00559 val_micro_f1score:0.77037\n",
            "epoch:47 loss:0.68376 hamming_loss:0.00479 micro_f1score:0.80699 val_hamming_loss:0.00544 val_micro_f1score:0.77116\n",
            "epoch:48 loss:0.69088 hamming_loss:0.00477 micro_f1score:0.80741 val_hamming_loss:0.00585 val_micro_f1score:0.76209\n",
            "epoch:49 loss:0.72660 hamming_loss:0.00514 micro_f1score:0.79465 val_hamming_loss:0.00595 val_micro_f1score:0.74182\n",
            "epoch:50 loss:0.71789 hamming_loss:0.00502 micro_f1score:0.79654 val_hamming_loss:0.00535 val_micro_f1score:0.77110\n",
            "epoch:51 loss:0.70847 hamming_loss:0.00496 micro_f1score:0.79833 val_hamming_loss:0.00559 val_micro_f1score:0.77579\n",
            "epoch:52 loss:0.67799 hamming_loss:0.00472 micro_f1score:0.81008 val_hamming_loss:0.00541 val_micro_f1score:0.77709\n",
            "epoch:53 loss:0.66631 hamming_loss:0.00471 micro_f1score:0.81120 val_hamming_loss:0.00555 val_micro_f1score:0.77940\n",
            "epoch:54 loss:0.78962 hamming_loss:0.00551 micro_f1score:0.77499 val_hamming_loss:0.00577 val_micro_f1score:0.77107\n",
            "epoch:55 loss:0.71546 hamming_loss:0.00495 micro_f1score:0.80021 val_hamming_loss:0.00539 val_micro_f1score:0.77198\n",
            "epoch:56 loss:0.69735 hamming_loss:0.00482 micro_f1score:0.80603 val_hamming_loss:0.00531 val_micro_f1score:0.78493\n",
            "epoch:57 loss:0.65964 hamming_loss:0.00450 micro_f1score:0.81941 val_hamming_loss:0.00532 val_micro_f1score:0.78156\n",
            "epoch:58 loss:0.64162 hamming_loss:0.00438 micro_f1score:0.82561 val_hamming_loss:0.00529 val_micro_f1score:0.78036\n",
            "epoch:59 loss:0.63977 hamming_loss:0.00434 micro_f1score:0.82755 val_hamming_loss:0.00545 val_micro_f1score:0.76894\n",
            "epoch:60 loss:0.64139 hamming_loss:0.00442 micro_f1score:0.82399 val_hamming_loss:0.00526 val_micro_f1score:0.78422\n",
            "epoch:61 loss:0.63438 hamming_loss:0.00434 micro_f1score:0.82801 val_hamming_loss:0.00521 val_micro_f1score:0.79009\n",
            "epoch:62 loss:0.62618 hamming_loss:0.00432 micro_f1score:0.82893 val_hamming_loss:0.00547 val_micro_f1score:0.78434\n",
            "epoch:63 loss:0.62322 hamming_loss:0.00421 micro_f1score:0.83381 val_hamming_loss:0.00540 val_micro_f1score:0.78191\n",
            "epoch:64 loss:0.61247 hamming_loss:0.00417 micro_f1score:0.83524 val_hamming_loss:0.00521 val_micro_f1score:0.79195\n",
            "epoch:65 loss:0.62259 hamming_loss:0.00421 micro_f1score:0.83415 val_hamming_loss:0.00535 val_micro_f1score:0.78363\n",
            "epoch:66 loss:0.62889 hamming_loss:0.00433 micro_f1score:0.82801 val_hamming_loss:0.00516 val_micro_f1score:0.79131\n",
            "epoch:67 loss:0.62066 hamming_loss:0.00425 micro_f1score:0.83268 val_hamming_loss:0.00537 val_micro_f1score:0.77552\n",
            "epoch:68 loss:0.61620 hamming_loss:0.00422 micro_f1score:0.83475 val_hamming_loss:0.00526 val_micro_f1score:0.78266\n",
            "epoch:69 loss:0.59422 hamming_loss:0.00396 micro_f1score:0.84465 val_hamming_loss:0.00530 val_micro_f1score:0.77995\n",
            "epoch:70 loss:0.60317 hamming_loss:0.00407 micro_f1score:0.84045 val_hamming_loss:0.00523 val_micro_f1score:0.78628\n",
            "epoch:71 loss:0.58566 hamming_loss:0.00381 micro_f1score:0.85083 val_hamming_loss:0.00516 val_micro_f1score:0.79503\n",
            "epoch:72 loss:0.59679 hamming_loss:0.00395 micro_f1score:0.84512 val_hamming_loss:0.00503 val_micro_f1score:0.79570\n",
            "epoch:73 loss:0.58012 hamming_loss:0.00384 micro_f1score:0.85109 val_hamming_loss:0.00529 val_micro_f1score:0.78295\n",
            "epoch:74 loss:0.57310 hamming_loss:0.00371 micro_f1score:0.85549 val_hamming_loss:0.00510 val_micro_f1score:0.79368\n",
            "epoch:75 loss:0.57824 hamming_loss:0.00376 micro_f1score:0.85418 val_hamming_loss:0.00523 val_micro_f1score:0.78744\n",
            "epoch:76 loss:0.57525 hamming_loss:0.00382 micro_f1score:0.85207 val_hamming_loss:0.00514 val_micro_f1score:0.79115\n",
            "epoch:77 loss:0.56109 hamming_loss:0.00363 micro_f1score:0.85876 val_hamming_loss:0.00506 val_micro_f1score:0.79578\n",
            "epoch:78 loss:0.55804 hamming_loss:0.00361 micro_f1score:0.86048 val_hamming_loss:0.00524 val_micro_f1score:0.78593\n",
            "epoch:79 loss:0.56882 hamming_loss:0.00368 micro_f1score:0.85760 val_hamming_loss:0.00498 val_micro_f1score:0.80071\n",
            "epoch:80 loss:0.56634 hamming_loss:0.00363 micro_f1score:0.86073 val_hamming_loss:0.00493 val_micro_f1score:0.80048\n",
            "epoch:81 loss:0.55605 hamming_loss:0.00357 micro_f1score:0.86210 val_hamming_loss:0.00498 val_micro_f1score:0.79731\n",
            "epoch:82 loss:0.54595 hamming_loss:0.00346 micro_f1score:0.86682 val_hamming_loss:0.00491 val_micro_f1score:0.80072\n",
            "epoch:83 loss:0.54560 hamming_loss:0.00344 micro_f1score:0.86779 val_hamming_loss:0.00485 val_micro_f1score:0.80474\n",
            "epoch:84 loss:0.53659 hamming_loss:0.00340 micro_f1score:0.86946 val_hamming_loss:0.00477 val_micro_f1score:0.80886\n",
            "epoch:85 loss:0.53674 hamming_loss:0.00333 micro_f1score:0.87224 val_hamming_loss:0.00474 val_micro_f1score:0.80957\n",
            "epoch:86 loss:0.52709 hamming_loss:0.00335 micro_f1score:0.87182 val_hamming_loss:0.00508 val_micro_f1score:0.78995\n",
            "epoch:87 loss:0.53445 hamming_loss:0.00336 micro_f1score:0.87120 val_hamming_loss:0.00478 val_micro_f1score:0.80540\n",
            "epoch:88 loss:0.52709 hamming_loss:0.00326 micro_f1score:0.87504 val_hamming_loss:0.00477 val_micro_f1score:0.80958\n",
            "epoch:89 loss:0.52322 hamming_loss:0.00323 micro_f1score:0.87671 val_hamming_loss:0.00462 val_micro_f1score:0.81562\n",
            "epoch:90 loss:0.51851 hamming_loss:0.00317 micro_f1score:0.87879 val_hamming_loss:0.00470 val_micro_f1score:0.81001\n",
            "epoch:91 loss:0.51244 hamming_loss:0.00312 micro_f1score:0.88161 val_hamming_loss:0.00474 val_micro_f1score:0.80390\n",
            "epoch:92 loss:0.52130 hamming_loss:0.00312 micro_f1score:0.88069 val_hamming_loss:0.00465 val_micro_f1score:0.81235\n",
            "epoch:93 loss:0.51073 hamming_loss:0.00310 micro_f1score:0.88134 val_hamming_loss:0.00463 val_micro_f1score:0.81842\n",
            "epoch:94 loss:0.55671 hamming_loss:0.00343 micro_f1score:0.86796 val_hamming_loss:0.00471 val_micro_f1score:0.81331\n",
            "epoch:95 loss:0.52820 hamming_loss:0.00330 micro_f1score:0.87340 val_hamming_loss:0.00467 val_micro_f1score:0.81477\n",
            "epoch:96 loss:0.52454 hamming_loss:0.00317 micro_f1score:0.87949 val_hamming_loss:0.00474 val_micro_f1score:0.80579\n",
            "epoch:97 loss:0.52028 hamming_loss:0.00313 micro_f1score:0.88097 val_hamming_loss:0.00467 val_micro_f1score:0.80881\n",
            "epoch:98 loss:0.50706 hamming_loss:0.00311 micro_f1score:0.88159 val_hamming_loss:0.00461 val_micro_f1score:0.81592\n",
            "epoch:99 loss:0.50621 hamming_loss:0.00299 micro_f1score:0.88626 val_hamming_loss:0.00458 val_micro_f1score:0.82130\n",
            "epoch:100 loss:0.54168 hamming_loss:0.00336 micro_f1score:0.87181 val_hamming_loss:0.00457 val_micro_f1score:0.81777\n",
            "epoch:101 loss:0.52226 hamming_loss:0.00321 micro_f1score:0.87739 val_hamming_loss:0.00480 val_micro_f1score:0.80212\n",
            "epoch:102 loss:0.50549 hamming_loss:0.00303 micro_f1score:0.88474 val_hamming_loss:0.00489 val_micro_f1score:0.80657\n",
            "epoch:103 loss:0.49019 hamming_loss:0.00291 micro_f1score:0.88972 val_hamming_loss:0.00455 val_micro_f1score:0.81607\n",
            "epoch:104 loss:0.48291 hamming_loss:0.00280 micro_f1score:0.89363 val_hamming_loss:0.00448 val_micro_f1score:0.82217\n",
            "epoch:105 loss:0.48142 hamming_loss:0.00278 micro_f1score:0.89513 val_hamming_loss:0.00455 val_micro_f1score:0.81584\n",
            "epoch:106 loss:0.47145 hamming_loss:0.00273 micro_f1score:0.89692 val_hamming_loss:0.00437 val_micro_f1score:0.82659\n",
            "epoch:107 loss:0.48261 hamming_loss:0.00276 micro_f1score:0.89590 val_hamming_loss:0.00457 val_micro_f1score:0.81745\n",
            "epoch:108 loss:0.46876 hamming_loss:0.00257 micro_f1score:0.90287 val_hamming_loss:0.00435 val_micro_f1score:0.82924\n",
            "epoch:109 loss:0.47022 hamming_loss:0.00264 micro_f1score:0.90049 val_hamming_loss:0.00438 val_micro_f1score:0.82751\n",
            "epoch:110 loss:0.46624 hamming_loss:0.00258 micro_f1score:0.90255 val_hamming_loss:0.00446 val_micro_f1score:0.82120\n",
            "epoch:111 loss:0.47446 hamming_loss:0.00269 micro_f1score:0.89832 val_hamming_loss:0.00437 val_micro_f1score:0.83016\n",
            "epoch:112 loss:0.46219 hamming_loss:0.00260 micro_f1score:0.90207 val_hamming_loss:0.00443 val_micro_f1score:0.82736\n",
            "epoch:113 loss:0.48283 hamming_loss:0.00290 micro_f1score:0.89049 val_hamming_loss:0.00444 val_micro_f1score:0.82520\n",
            "epoch:114 loss:0.47223 hamming_loss:0.00269 micro_f1score:0.89838 val_hamming_loss:0.00441 val_micro_f1score:0.82780\n",
            "epoch:115 loss:0.48154 hamming_loss:0.00274 micro_f1score:0.89656 val_hamming_loss:0.00454 val_micro_f1score:0.82341\n",
            "epoch:116 loss:0.47652 hamming_loss:0.00270 micro_f1score:0.89799 val_hamming_loss:0.00449 val_micro_f1score:0.82805\n",
            "epoch:117 loss:0.49227 hamming_loss:0.00296 micro_f1score:0.88825 val_hamming_loss:0.00467 val_micro_f1score:0.81896\n",
            "epoch:118 loss:0.91832 hamming_loss:0.00600 micro_f1score:0.77136 val_hamming_loss:0.00619 val_micro_f1score:0.73403\n",
            "epoch:119 loss:0.95260 hamming_loss:0.00683 micro_f1score:0.73327 val_hamming_loss:0.00523 val_micro_f1score:0.78487\n",
            "epoch:120 loss:0.67791 hamming_loss:0.00460 micro_f1score:0.82130 val_hamming_loss:0.00474 val_micro_f1score:0.80957\n",
            "epoch:121 loss:0.59725 hamming_loss:0.00393 micro_f1score:0.84886 val_hamming_loss:0.00458 val_micro_f1score:0.81699\n",
            "epoch:122 loss:0.55885 hamming_loss:0.00344 micro_f1score:0.86856 val_hamming_loss:0.00449 val_micro_f1score:0.82120\n",
            "epoch:123 loss:0.53690 hamming_loss:0.00336 micro_f1score:0.87201 val_hamming_loss:0.00455 val_micro_f1score:0.81518\n",
            "epoch:124 loss:0.52210 hamming_loss:0.00317 micro_f1score:0.87958 val_hamming_loss:0.00453 val_micro_f1score:0.81557\n",
            "epoch:125 loss:0.50015 hamming_loss:0.00294 micro_f1score:0.88836 val_hamming_loss:0.00442 val_micro_f1score:0.82052\n",
            "epoch:126 loss:0.48804 hamming_loss:0.00278 micro_f1score:0.89449 val_hamming_loss:0.00436 val_micro_f1score:0.82691\n",
            "epoch:127 loss:0.48076 hamming_loss:0.00276 micro_f1score:0.89558 val_hamming_loss:0.00438 val_micro_f1score:0.82400\n",
            "epoch:128 loss:0.47811 hamming_loss:0.00276 micro_f1score:0.89614 val_hamming_loss:0.00447 val_micro_f1score:0.81815\n",
            "epoch:129 loss:0.47523 hamming_loss:0.00272 micro_f1score:0.89716 val_hamming_loss:0.00434 val_micro_f1score:0.82484\n",
            "epoch:130 loss:0.48023 hamming_loss:0.00271 micro_f1score:0.89783 val_hamming_loss:0.00441 val_micro_f1score:0.82273\n",
            "epoch:131 loss:0.46579 hamming_loss:0.00259 micro_f1score:0.90225 val_hamming_loss:0.00432 val_micro_f1score:0.82551\n",
            "epoch:132 loss:0.46131 hamming_loss:0.00262 micro_f1score:0.90152 val_hamming_loss:0.00444 val_micro_f1score:0.81961\n",
            "epoch:133 loss:0.48616 hamming_loss:0.00286 micro_f1score:0.89208 val_hamming_loss:0.00442 val_micro_f1score:0.82143\n",
            "epoch:134 loss:0.46755 hamming_loss:0.00262 micro_f1score:0.90125 val_hamming_loss:0.00436 val_micro_f1score:0.82885\n",
            "epoch:135 loss:0.46525 hamming_loss:0.00258 micro_f1score:0.90266 val_hamming_loss:0.00433 val_micro_f1score:0.83113\n",
            "epoch:136 loss:0.46266 hamming_loss:0.00257 micro_f1score:0.90357 val_hamming_loss:0.00433 val_micro_f1score:0.83004\n",
            "epoch:137 loss:0.44969 hamming_loss:0.00243 micro_f1score:0.90833 val_hamming_loss:0.00417 val_micro_f1score:0.83761\n",
            "epoch:138 loss:0.44122 hamming_loss:0.00235 micro_f1score:0.91179 val_hamming_loss:0.00424 val_micro_f1score:0.83128\n",
            "epoch:139 loss:0.45067 hamming_loss:0.00247 micro_f1score:0.90743 val_hamming_loss:0.00418 val_micro_f1score:0.83457\n",
            "epoch:140 loss:0.44491 hamming_loss:0.00250 micro_f1score:0.90658 val_hamming_loss:0.00441 val_micro_f1score:0.82261\n",
            "epoch:141 loss:0.44286 hamming_loss:0.00237 micro_f1score:0.91115 val_hamming_loss:0.00436 val_micro_f1score:0.82311\n",
            "epoch:142 loss:0.44338 hamming_loss:0.00233 micro_f1score:0.91251 val_hamming_loss:0.00439 val_micro_f1score:0.82383\n",
            "epoch:143 loss:0.45964 hamming_loss:0.00250 micro_f1score:0.90578 val_hamming_loss:0.00424 val_micro_f1score:0.83574\n",
            "epoch:144 loss:0.44330 hamming_loss:0.00235 micro_f1score:0.91204 val_hamming_loss:0.00414 val_micro_f1score:0.83977\n",
            "epoch:145 loss:0.46269 hamming_loss:0.00255 micro_f1score:0.90443 val_hamming_loss:0.00428 val_micro_f1score:0.83152\n",
            "epoch:146 loss:0.44654 hamming_loss:0.00238 micro_f1score:0.91100 val_hamming_loss:0.00429 val_micro_f1score:0.82807\n",
            "epoch:147 loss:0.44730 hamming_loss:0.00236 micro_f1score:0.91142 val_hamming_loss:0.00418 val_micro_f1score:0.83319\n",
            "epoch:148 loss:0.43374 hamming_loss:0.00227 micro_f1score:0.91495 val_hamming_loss:0.00417 val_micro_f1score:0.83365\n",
            "epoch:149 loss:0.43516 hamming_loss:0.00224 micro_f1score:0.91617 val_hamming_loss:0.00427 val_micro_f1score:0.83059\n",
            "epoch:150 loss:0.43235 hamming_loss:0.00228 micro_f1score:0.91460 val_hamming_loss:0.00428 val_micro_f1score:0.83118\n",
            "epoch:151 loss:0.43376 hamming_loss:0.00229 micro_f1score:0.91421 val_hamming_loss:0.00426 val_micro_f1score:0.83139\n",
            "epoch:152 loss:0.42642 hamming_loss:0.00210 micro_f1score:0.92178 val_hamming_loss:0.00420 val_micro_f1score:0.83216\n",
            "epoch:153 loss:0.43579 hamming_loss:0.00225 micro_f1score:0.91546 val_hamming_loss:0.00415 val_micro_f1score:0.83583\n",
            "epoch:154 loss:0.42407 hamming_loss:0.00218 micro_f1score:0.91879 val_hamming_loss:0.00420 val_micro_f1score:0.83449\n",
            "epoch:155 loss:0.42131 hamming_loss:0.00214 micro_f1score:0.92017 val_hamming_loss:0.00413 val_micro_f1score:0.83767\n",
            "epoch:156 loss:0.41227 hamming_loss:0.00193 micro_f1score:0.92823 val_hamming_loss:0.00423 val_micro_f1score:0.83273\n",
            "epoch:157 loss:0.41143 hamming_loss:0.00198 micro_f1score:0.92608 val_hamming_loss:0.00411 val_micro_f1score:0.83863\n",
            "epoch:158 loss:0.41264 hamming_loss:0.00196 micro_f1score:0.92669 val_hamming_loss:0.00419 val_micro_f1score:0.83817\n",
            "epoch:159 loss:0.41688 hamming_loss:0.00207 micro_f1score:0.92311 val_hamming_loss:0.00418 val_micro_f1score:0.83643\n",
            "epoch:160 loss:0.40738 hamming_loss:0.00199 micro_f1score:0.92602 val_hamming_loss:0.00422 val_micro_f1score:0.82970\n",
            "epoch:161 loss:0.41158 hamming_loss:0.00203 micro_f1score:0.92458 val_hamming_loss:0.00417 val_micro_f1score:0.83382\n",
            "epoch:162 loss:0.40416 hamming_loss:0.00196 micro_f1score:0.92699 val_hamming_loss:0.00412 val_micro_f1score:0.83486\n",
            "epoch:163 loss:0.40604 hamming_loss:0.00190 micro_f1score:0.92907 val_hamming_loss:0.00404 val_micro_f1score:0.83922\n",
            "epoch:164 loss:0.41078 hamming_loss:0.00197 micro_f1score:0.92668 val_hamming_loss:0.00406 val_micro_f1score:0.84257\n",
            "epoch:165 loss:0.41185 hamming_loss:0.00202 micro_f1score:0.92516 val_hamming_loss:0.00410 val_micro_f1score:0.83761\n",
            "epoch:166 loss:0.41095 hamming_loss:0.00202 micro_f1score:0.92484 val_hamming_loss:0.00424 val_micro_f1score:0.83064\n",
            "epoch:167 loss:0.41761 hamming_loss:0.00212 micro_f1score:0.92077 val_hamming_loss:0.00411 val_micro_f1score:0.83916\n",
            "epoch:168 loss:0.41376 hamming_loss:0.00206 micro_f1score:0.92331 val_hamming_loss:0.00413 val_micro_f1score:0.83732\n",
            "epoch:169 loss:0.40310 hamming_loss:0.00193 micro_f1score:0.92819 val_hamming_loss:0.00426 val_micro_f1score:0.83514\n",
            "epoch:170 loss:0.41144 hamming_loss:0.00203 micro_f1score:0.92428 val_hamming_loss:0.00411 val_micro_f1score:0.83992\n",
            "epoch:171 loss:0.40847 hamming_loss:0.00194 micro_f1score:0.92792 val_hamming_loss:0.00405 val_micro_f1score:0.84233\n",
            "epoch:172 loss:0.40464 hamming_loss:0.00187 micro_f1score:0.93047 val_hamming_loss:0.00400 val_micro_f1score:0.84487\n",
            "epoch:173 loss:0.40262 hamming_loss:0.00192 micro_f1score:0.92872 val_hamming_loss:0.00399 val_micro_f1score:0.84343\n",
            "epoch:174 loss:0.39650 hamming_loss:0.00183 micro_f1score:0.93220 val_hamming_loss:0.00411 val_micro_f1score:0.83578\n",
            "epoch:175 loss:0.41288 hamming_loss:0.00208 micro_f1score:0.92254 val_hamming_loss:0.00414 val_micro_f1score:0.83672\n",
            "epoch:176 loss:0.40571 hamming_loss:0.00189 micro_f1score:0.92953 val_hamming_loss:0.00404 val_micro_f1score:0.84402\n",
            "epoch:177 loss:0.40354 hamming_loss:0.00193 micro_f1score:0.92834 val_hamming_loss:0.00412 val_micro_f1score:0.83952\n",
            "epoch:178 loss:0.40072 hamming_loss:0.00192 micro_f1score:0.92894 val_hamming_loss:0.00405 val_micro_f1score:0.84159\n",
            "epoch:179 loss:0.40818 hamming_loss:0.00199 micro_f1score:0.92621 val_hamming_loss:0.00421 val_micro_f1score:0.83080\n",
            "epoch:180 loss:0.40840 hamming_loss:0.00197 micro_f1score:0.92680 val_hamming_loss:0.00423 val_micro_f1score:0.83115\n",
            "epoch:181 loss:0.40186 hamming_loss:0.00189 micro_f1score:0.92981 val_hamming_loss:0.00424 val_micro_f1score:0.82875\n",
            "epoch:182 loss:0.42716 hamming_loss:0.00215 micro_f1score:0.92031 val_hamming_loss:0.00445 val_micro_f1score:0.81840\n",
            "epoch:183 loss:0.41319 hamming_loss:0.00202 micro_f1score:0.92483 val_hamming_loss:0.00398 val_micro_f1score:0.84387\n",
            "epoch:184 loss:0.39878 hamming_loss:0.00183 micro_f1score:0.93194 val_hamming_loss:0.00408 val_micro_f1score:0.84234\n",
            "epoch:185 loss:0.39246 hamming_loss:0.00179 micro_f1score:0.93352 val_hamming_loss:0.00397 val_micro_f1score:0.84553\n",
            "epoch:186 loss:0.39732 hamming_loss:0.00184 micro_f1score:0.93200 val_hamming_loss:0.00409 val_micro_f1score:0.83847\n",
            "epoch:187 loss:0.40187 hamming_loss:0.00181 micro_f1score:0.93281 val_hamming_loss:0.00400 val_micro_f1score:0.84447\n",
            "epoch:188 loss:0.46713 hamming_loss:0.00243 micro_f1score:0.90929 val_hamming_loss:0.00482 val_micro_f1score:0.80802\n",
            "epoch:189 loss:0.46132 hamming_loss:0.00250 micro_f1score:0.90658 val_hamming_loss:0.00424 val_micro_f1score:0.83331\n",
            "epoch:190 loss:0.41209 hamming_loss:0.00203 micro_f1score:0.92448 val_hamming_loss:0.00415 val_micro_f1score:0.83740\n",
            "epoch:191 loss:0.40527 hamming_loss:0.00194 micro_f1score:0.92798 val_hamming_loss:0.00393 val_micro_f1score:0.84534\n",
            "epoch:192 loss:0.38986 hamming_loss:0.00177 micro_f1score:0.93450 val_hamming_loss:0.00406 val_micro_f1score:0.83916\n",
            "epoch:193 loss:0.39785 hamming_loss:0.00184 micro_f1score:0.93180 val_hamming_loss:0.00412 val_micro_f1score:0.83782\n",
            "epoch:194 loss:0.41875 hamming_loss:0.00204 micro_f1score:0.92429 val_hamming_loss:0.00410 val_micro_f1score:0.83862\n",
            "epoch:195 loss:0.39764 hamming_loss:0.00183 micro_f1score:0.93191 val_hamming_loss:0.00411 val_micro_f1score:0.84030\n",
            "epoch:196 loss:0.38460 hamming_loss:0.00171 micro_f1score:0.93639 val_hamming_loss:0.00395 val_micro_f1score:0.84762\n",
            "epoch:197 loss:0.38200 hamming_loss:0.00169 micro_f1score:0.93747 val_hamming_loss:0.00387 val_micro_f1score:0.84933\n",
            "epoch:198 loss:0.38432 hamming_loss:0.00167 micro_f1score:0.93831 val_hamming_loss:0.00397 val_micro_f1score:0.84440\n",
            "epoch:199 loss:0.37849 hamming_loss:0.00163 micro_f1score:0.93948 val_hamming_loss:0.00398 val_micro_f1score:0.84673\n",
            "epoch:200 loss:0.38410 hamming_loss:0.00167 micro_f1score:0.93803 val_hamming_loss:0.00400 val_micro_f1score:0.84684\n",
            "epoch:201 loss:0.38746 hamming_loss:0.00166 micro_f1score:0.93856 val_hamming_loss:0.00414 val_micro_f1score:0.83809\n",
            "epoch:202 loss:0.38791 hamming_loss:0.00171 micro_f1score:0.93657 val_hamming_loss:0.00398 val_micro_f1score:0.84472\n",
            "epoch:203 loss:0.38453 hamming_loss:0.00169 micro_f1score:0.93738 val_hamming_loss:0.00416 val_micro_f1score:0.83755\n",
            "epoch:204 loss:0.39313 hamming_loss:0.00177 micro_f1score:0.93465 val_hamming_loss:0.00402 val_micro_f1score:0.84134\n",
            "epoch:205 loss:0.37885 hamming_loss:0.00158 micro_f1score:0.94163 val_hamming_loss:0.00395 val_micro_f1score:0.84405\n",
            "epoch:206 loss:0.38778 hamming_loss:0.00159 micro_f1score:0.94098 val_hamming_loss:0.00415 val_micro_f1score:0.83886\n",
            "epoch:207 loss:0.39438 hamming_loss:0.00172 micro_f1score:0.93622 val_hamming_loss:0.00412 val_micro_f1score:0.83792\n",
            "epoch:208 loss:0.38538 hamming_loss:0.00165 micro_f1score:0.93891 val_hamming_loss:0.00405 val_micro_f1score:0.83911\n",
            "epoch:209 loss:0.38366 hamming_loss:0.00160 micro_f1score:0.94082 val_hamming_loss:0.00393 val_micro_f1score:0.84735\n",
            "epoch:210 loss:0.37759 hamming_loss:0.00163 micro_f1score:0.93986 val_hamming_loss:0.00397 val_micro_f1score:0.84636\n",
            "epoch:211 loss:0.37665 hamming_loss:0.00155 micro_f1score:0.94245 val_hamming_loss:0.00404 val_micro_f1score:0.84017\n",
            "epoch:212 loss:0.38530 hamming_loss:0.00169 micro_f1score:0.93722 val_hamming_loss:0.00407 val_micro_f1score:0.84336\n",
            "epoch:213 loss:0.39074 hamming_loss:0.00176 micro_f1score:0.93522 val_hamming_loss:0.00403 val_micro_f1score:0.84165\n",
            "epoch:214 loss:0.38117 hamming_loss:0.00165 micro_f1score:0.93894 val_hamming_loss:0.00413 val_micro_f1score:0.83400\n",
            "epoch:215 loss:0.38915 hamming_loss:0.00172 micro_f1score:0.93610 val_hamming_loss:0.00404 val_micro_f1score:0.84583\n",
            "epoch:216 loss:0.39983 hamming_loss:0.00175 micro_f1score:0.93510 val_hamming_loss:0.00407 val_micro_f1score:0.84115\n",
            "epoch:217 loss:0.41137 hamming_loss:0.00196 micro_f1score:0.92718 val_hamming_loss:0.00430 val_micro_f1score:0.83675\n",
            "epoch:218 loss:0.39792 hamming_loss:0.00176 micro_f1score:0.93473 val_hamming_loss:0.00402 val_micro_f1score:0.84346\n",
            "epoch:219 loss:0.42713 hamming_loss:0.00206 micro_f1score:0.92373 val_hamming_loss:0.00396 val_micro_f1score:0.84475\n",
            "epoch:220 loss:0.40406 hamming_loss:0.00183 micro_f1score:0.93234 val_hamming_loss:0.00422 val_micro_f1score:0.83095\n",
            "epoch:221 loss:0.41089 hamming_loss:0.00193 micro_f1score:0.92861 val_hamming_loss:0.00405 val_micro_f1score:0.84115\n",
            "epoch:222 loss:0.39159 hamming_loss:0.00177 micro_f1score:0.93430 val_hamming_loss:0.00401 val_micro_f1score:0.84379\n",
            "epoch:223 loss:0.38443 hamming_loss:0.00165 micro_f1score:0.93885 val_hamming_loss:0.00400 val_micro_f1score:0.84148\n",
            "epoch:224 loss:0.37399 hamming_loss:0.00151 micro_f1score:0.94388 val_hamming_loss:0.00411 val_micro_f1score:0.83905\n",
            "epoch:225 loss:0.38472 hamming_loss:0.00164 micro_f1score:0.93933 val_hamming_loss:0.00397 val_micro_f1score:0.84266\n",
            "epoch:226 loss:0.37034 hamming_loss:0.00150 micro_f1score:0.94463 val_hamming_loss:0.00396 val_micro_f1score:0.84398\n",
            "epoch:227 loss:0.36748 hamming_loss:0.00144 micro_f1score:0.94656 val_hamming_loss:0.00395 val_micro_f1score:0.84480\n",
            "epoch:228 loss:0.36563 hamming_loss:0.00142 micro_f1score:0.94745 val_hamming_loss:0.00396 val_micro_f1score:0.84478\n",
            "epoch:229 loss:0.37377 hamming_loss:0.00154 micro_f1score:0.94311 val_hamming_loss:0.00398 val_micro_f1score:0.84373\n",
            "epoch:230 loss:0.36650 hamming_loss:0.00141 micro_f1score:0.94789 val_hamming_loss:0.00392 val_micro_f1score:0.84810\n",
            "epoch:231 loss:0.36457 hamming_loss:0.00136 micro_f1score:0.94957 val_hamming_loss:0.00387 val_micro_f1score:0.84915\n",
            "epoch:232 loss:0.36276 hamming_loss:0.00140 micro_f1score:0.94846 val_hamming_loss:0.00396 val_micro_f1score:0.84636\n",
            "epoch:233 loss:0.36440 hamming_loss:0.00142 micro_f1score:0.94770 val_hamming_loss:0.00394 val_micro_f1score:0.84470\n",
            "epoch:234 loss:0.36593 hamming_loss:0.00142 micro_f1score:0.94762 val_hamming_loss:0.00404 val_micro_f1score:0.83793\n",
            "epoch:235 loss:0.37213 hamming_loss:0.00151 micro_f1score:0.94402 val_hamming_loss:0.00387 val_micro_f1score:0.85009\n",
            "epoch:236 loss:0.36151 hamming_loss:0.00137 micro_f1score:0.94932 val_hamming_loss:0.00383 val_micro_f1score:0.85100\n",
            "epoch:237 loss:0.36398 hamming_loss:0.00141 micro_f1score:0.94800 val_hamming_loss:0.00389 val_micro_f1score:0.84812\n",
            "epoch:238 loss:0.36658 hamming_loss:0.00140 micro_f1score:0.94826 val_hamming_loss:0.00409 val_micro_f1score:0.83729\n",
            "epoch:239 loss:0.38965 hamming_loss:0.00164 micro_f1score:0.93954 val_hamming_loss:0.00394 val_micro_f1score:0.84511\n",
            "epoch:240 loss:0.39871 hamming_loss:0.00172 micro_f1score:0.93629 val_hamming_loss:0.00392 val_micro_f1score:0.84581\n",
            "epoch:241 loss:0.38335 hamming_loss:0.00163 micro_f1score:0.93970 val_hamming_loss:0.00388 val_micro_f1score:0.84903\n",
            "epoch:242 loss:0.46088 hamming_loss:0.00221 micro_f1score:0.91858 val_hamming_loss:0.00552 val_micro_f1score:0.76195\n",
            "epoch:243 loss:0.58273 hamming_loss:0.00351 micro_f1score:0.86897 val_hamming_loss:0.00439 val_micro_f1score:0.82106\n",
            "epoch:244 loss:0.47818 hamming_loss:0.00255 micro_f1score:0.90505 val_hamming_loss:0.00423 val_micro_f1score:0.83434\n",
            "epoch:245 loss:0.41992 hamming_loss:0.00200 micro_f1score:0.92586 val_hamming_loss:0.00397 val_micro_f1score:0.84387\n",
            "epoch:246 loss:0.40974 hamming_loss:0.00188 micro_f1score:0.93037 val_hamming_loss:0.00393 val_micro_f1score:0.84522\n",
            "epoch:247 loss:0.38853 hamming_loss:0.00163 micro_f1score:0.93965 val_hamming_loss:0.00399 val_micro_f1score:0.84087\n",
            "epoch:248 loss:0.38884 hamming_loss:0.00165 micro_f1score:0.93896 val_hamming_loss:0.00397 val_micro_f1score:0.84584\n",
            "epoch:249 loss:0.38684 hamming_loss:0.00161 micro_f1score:0.94052 val_hamming_loss:0.00391 val_micro_f1score:0.84561\n",
            "epoch:250 loss:0.37629 hamming_loss:0.00152 micro_f1score:0.94356 val_hamming_loss:0.00403 val_micro_f1score:0.84074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJ-Lonl0f0Ih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}